{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from goalguru.statsbombs_package.data_processor import load_all_seasons_past_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9_27.csv loaded locally\n",
      "37_90.csv loaded locally\n",
      "37_42.csv loaded locally\n",
      "37_4.csv loaded locally\n",
      "43_106.csv loaded locally\n",
      "43_3.csv loaded locally\n",
      "1238_108.csv loaded locally\n",
      "11_27.csv loaded locally\n",
      "7_27.csv loaded locally\n",
      "2_27.csv loaded locally\n",
      "12_27.csv loaded locally\n",
      "55_43.csv loaded locally\n",
      "72_107.csv loaded locally\n",
      "72_30.csv loaded locally\n",
      "53_106.csv loaded locally\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2590, 38)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = load_all_seasons_past_info(save_concat=False)\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['match_id', 'target', 'pass_completed_home_all_past',\n",
       "       'pass_total_home_all_past', 'pass_precision_home_all_past',\n",
       "       'shot_on_target_home_all_past', 'shot_goal_home_all_past',\n",
       "       'shot_xg_home_all_past', 'shot_total_home_all_past',\n",
       "       'shot_precision_home_all_past', 'shot_conversion_home_all_past',\n",
       "       'pass_completed_home_last_10', 'pass_total_home_last_10',\n",
       "       'pass_precision_home_last_10', 'shot_on_target_home_last_10',\n",
       "       'shot_goal_home_last_10', 'shot_xg_home_last_10',\n",
       "       'shot_total_home_last_10', 'shot_precision_home_last_10',\n",
       "       'shot_conversion_home_last_10', 'pass_completed_away_all_past',\n",
       "       'pass_total_away_all_past', 'pass_precision_away_all_past',\n",
       "       'shot_on_target_away_all_past', 'shot_goal_away_all_past',\n",
       "       'shot_xg_away_all_past', 'shot_total_away_all_past',\n",
       "       'shot_precision_away_all_past', 'shot_conversion_away_all_past',\n",
       "       'pass_completed_away_last_10', 'pass_total_away_last_10',\n",
       "       'pass_precision_away_last_10', 'shot_on_target_away_last_10',\n",
       "       'shot_goal_away_last_10', 'shot_xg_away_last_10',\n",
       "       'shot_total_away_last_10', 'shot_precision_away_last_10',\n",
       "       'shot_conversion_away_last_10'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2434, 36), (2434,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_not_na = all_data.dropna(axis=0, how='any')\n",
    "X = all_data_not_na.drop(columns=['match_id', 'target'])\n",
    "y = all_data_not_na['target']\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pass_completed_home_all_past</th>\n",
       "      <th>pass_total_home_all_past</th>\n",
       "      <th>pass_precision_home_all_past</th>\n",
       "      <th>shot_on_target_home_all_past</th>\n",
       "      <th>shot_goal_home_all_past</th>\n",
       "      <th>shot_xg_home_all_past</th>\n",
       "      <th>shot_total_home_all_past</th>\n",
       "      <th>shot_precision_home_all_past</th>\n",
       "      <th>shot_conversion_home_all_past</th>\n",
       "      <th>pass_completed_home_last_10</th>\n",
       "      <th>...</th>\n",
       "      <th>shot_conversion_away_all_past</th>\n",
       "      <th>pass_completed_away_last_10</th>\n",
       "      <th>pass_total_away_last_10</th>\n",
       "      <th>pass_precision_away_last_10</th>\n",
       "      <th>shot_on_target_away_last_10</th>\n",
       "      <th>shot_goal_away_last_10</th>\n",
       "      <th>shot_xg_away_last_10</th>\n",
       "      <th>shot_total_away_last_10</th>\n",
       "      <th>shot_precision_away_last_10</th>\n",
       "      <th>shot_conversion_away_last_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>361.685714</td>\n",
       "      <td>480.285714</td>\n",
       "      <td>0.748163</td>\n",
       "      <td>7.914286</td>\n",
       "      <td>1.342857</td>\n",
       "      <td>1.367204</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>0.579036</td>\n",
       "      <td>0.098571</td>\n",
       "      <td>358.600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116458</td>\n",
       "      <td>480.700</td>\n",
       "      <td>591.400</td>\n",
       "      <td>0.807767</td>\n",
       "      <td>8.300</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.703411</td>\n",
       "      <td>14.500</td>\n",
       "      <td>0.595837</td>\n",
       "      <td>0.137152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>438.785714</td>\n",
       "      <td>541.214286</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>8.428571</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.536852</td>\n",
       "      <td>14.714286</td>\n",
       "      <td>0.572389</td>\n",
       "      <td>0.102047</td>\n",
       "      <td>432.300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105400</td>\n",
       "      <td>371.500</td>\n",
       "      <td>483.200</td>\n",
       "      <td>0.759984</td>\n",
       "      <td>7.600</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.380306</td>\n",
       "      <td>12.800</td>\n",
       "      <td>0.601868</td>\n",
       "      <td>0.128652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>376.846154</td>\n",
       "      <td>486.384615</td>\n",
       "      <td>0.771788</td>\n",
       "      <td>5.384615</td>\n",
       "      <td>1.230769</td>\n",
       "      <td>1.259066</td>\n",
       "      <td>11.307692</td>\n",
       "      <td>0.471189</td>\n",
       "      <td>0.122260</td>\n",
       "      <td>395.600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115646</td>\n",
       "      <td>374.300</td>\n",
       "      <td>486.600</td>\n",
       "      <td>0.766126</td>\n",
       "      <td>7.000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.177469</td>\n",
       "      <td>12.200</td>\n",
       "      <td>0.570802</td>\n",
       "      <td>0.137092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>272.250000</td>\n",
       "      <td>399.750000</td>\n",
       "      <td>0.673977</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.302680</td>\n",
       "      <td>13.875000</td>\n",
       "      <td>0.510572</td>\n",
       "      <td>0.061848</td>\n",
       "      <td>272.250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195640</td>\n",
       "      <td>641.250</td>\n",
       "      <td>730.625</td>\n",
       "      <td>0.874480</td>\n",
       "      <td>11.375</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.940361</td>\n",
       "      <td>19.000</td>\n",
       "      <td>0.594374</td>\n",
       "      <td>0.195640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>342.727273</td>\n",
       "      <td>450.181818</td>\n",
       "      <td>0.759330</td>\n",
       "      <td>6.181818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963164</td>\n",
       "      <td>11.636364</td>\n",
       "      <td>0.538517</td>\n",
       "      <td>0.089545</td>\n",
       "      <td>345.200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114039</td>\n",
       "      <td>321.200</td>\n",
       "      <td>440.800</td>\n",
       "      <td>0.723977</td>\n",
       "      <td>6.200</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.006067</td>\n",
       "      <td>11.800</td>\n",
       "      <td>0.539160</td>\n",
       "      <td>0.100443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>394.727273</td>\n",
       "      <td>500.727273</td>\n",
       "      <td>0.786710</td>\n",
       "      <td>8.090909</td>\n",
       "      <td>1.090909</td>\n",
       "      <td>0.885508</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.540452</td>\n",
       "      <td>0.071964</td>\n",
       "      <td>390.600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063582</td>\n",
       "      <td>493.300</td>\n",
       "      <td>582.600</td>\n",
       "      <td>0.841459</td>\n",
       "      <td>9.300</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.760585</td>\n",
       "      <td>18.200</td>\n",
       "      <td>0.504216</td>\n",
       "      <td>0.069941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>315.818182</td>\n",
       "      <td>441.151515</td>\n",
       "      <td>0.710720</td>\n",
       "      <td>6.696970</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>1.109629</td>\n",
       "      <td>11.696970</td>\n",
       "      <td>0.565661</td>\n",
       "      <td>0.088019</td>\n",
       "      <td>311.800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109148</td>\n",
       "      <td>398.900</td>\n",
       "      <td>518.200</td>\n",
       "      <td>0.762954</td>\n",
       "      <td>7.400</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.457520</td>\n",
       "      <td>13.100</td>\n",
       "      <td>0.562998</td>\n",
       "      <td>0.116797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>359.625000</td>\n",
       "      <td>471.375000</td>\n",
       "      <td>0.751602</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.846534</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.522148</td>\n",
       "      <td>0.061111</td>\n",
       "      <td>359.625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144494</td>\n",
       "      <td>299.875</td>\n",
       "      <td>417.875</td>\n",
       "      <td>0.706425</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.984060</td>\n",
       "      <td>9.375</td>\n",
       "      <td>0.550496</td>\n",
       "      <td>0.144494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>333.138889</td>\n",
       "      <td>456.027778</td>\n",
       "      <td>0.723556</td>\n",
       "      <td>6.555556</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>1.326958</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>0.580807</td>\n",
       "      <td>0.099066</td>\n",
       "      <td>300.500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071711</td>\n",
       "      <td>384.300</td>\n",
       "      <td>493.400</td>\n",
       "      <td>0.770045</td>\n",
       "      <td>7.500</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.037309</td>\n",
       "      <td>12.000</td>\n",
       "      <td>0.596746</td>\n",
       "      <td>0.097073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>580.000000</td>\n",
       "      <td>710.000000</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>5.953466</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>580.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>169.000</td>\n",
       "      <td>279.000</td>\n",
       "      <td>0.605735</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117022</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1703 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pass_completed_home_all_past  pass_total_home_all_past  \\\n",
       "1987                    361.685714                480.285714   \n",
       "1517                    438.785714                541.214286   \n",
       "1443                    376.846154                486.384615   \n",
       "236                     272.250000                399.750000   \n",
       "2294                    342.727273                450.181818   \n",
       "...                            ...                       ...   \n",
       "2292                    394.727273                500.727273   \n",
       "901                     315.818182                441.151515   \n",
       "1166                    359.625000                471.375000   \n",
       "1289                    333.138889                456.027778   \n",
       "2532                    580.000000                710.000000   \n",
       "\n",
       "      pass_precision_home_all_past  shot_on_target_home_all_past  \\\n",
       "1987                      0.748163                      7.914286   \n",
       "1517                      0.806938                      8.428571   \n",
       "1443                      0.771788                      5.384615   \n",
       "236                       0.673977                      7.250000   \n",
       "2294                      0.759330                      6.181818   \n",
       "...                            ...                           ...   \n",
       "2292                      0.786710                      8.090909   \n",
       "901                       0.710720                      6.696970   \n",
       "1166                      0.751602                      6.250000   \n",
       "1289                      0.723556                      6.555556   \n",
       "2532                      0.816901                     31.000000   \n",
       "\n",
       "      shot_goal_home_all_past  shot_xg_home_all_past  \\\n",
       "1987                 1.342857               1.367204   \n",
       "1517                 1.428571               1.536852   \n",
       "1443                 1.230769               1.259066   \n",
       "236                  0.875000               1.302680   \n",
       "2294                 1.000000               0.963164   \n",
       "...                       ...                    ...   \n",
       "2292                 1.090909               0.885508   \n",
       "901                  0.878788               1.109629   \n",
       "1166                 0.625000               0.846534   \n",
       "1289                 1.083333               1.326958   \n",
       "2532                13.000000               5.953466   \n",
       "\n",
       "      shot_total_home_all_past  shot_precision_home_all_past  \\\n",
       "1987                 13.800000                      0.579036   \n",
       "1517                 14.714286                      0.572389   \n",
       "1443                 11.307692                      0.471189   \n",
       "236                  13.875000                      0.510572   \n",
       "2294                 11.636364                      0.538517   \n",
       "...                        ...                           ...   \n",
       "2292                 15.000000                      0.540452   \n",
       "901                  11.696970                      0.565661   \n",
       "1166                 12.000000                      0.522148   \n",
       "1289                 11.333333                      0.580807   \n",
       "2532                 39.000000                      0.794872   \n",
       "\n",
       "      shot_conversion_home_all_past  pass_completed_home_last_10  ...  \\\n",
       "1987                       0.098571                      358.600  ...   \n",
       "1517                       0.102047                      432.300  ...   \n",
       "1443                       0.122260                      395.600  ...   \n",
       "236                        0.061848                      272.250  ...   \n",
       "2294                       0.089545                      345.200  ...   \n",
       "...                             ...                          ...  ...   \n",
       "2292                       0.071964                      390.600  ...   \n",
       "901                        0.088019                      311.800  ...   \n",
       "1166                       0.061111                      359.625  ...   \n",
       "1289                       0.099066                      300.500  ...   \n",
       "2532                       0.333333                      580.000  ...   \n",
       "\n",
       "      shot_conversion_away_all_past  pass_completed_away_last_10  \\\n",
       "1987                       0.116458                      480.700   \n",
       "1517                       0.105400                      371.500   \n",
       "1443                       0.115646                      374.300   \n",
       "236                        0.195640                      641.250   \n",
       "2294                       0.114039                      321.200   \n",
       "...                             ...                          ...   \n",
       "2292                       0.063582                      493.300   \n",
       "901                        0.109148                      398.900   \n",
       "1166                       0.144494                      299.875   \n",
       "1289                       0.071711                      384.300   \n",
       "2532                       0.000000                      169.000   \n",
       "\n",
       "      pass_total_away_last_10  pass_precision_away_last_10  \\\n",
       "1987                  591.400                     0.807767   \n",
       "1517                  483.200                     0.759984   \n",
       "1443                  486.600                     0.766126   \n",
       "236                   730.625                     0.874480   \n",
       "2294                  440.800                     0.723977   \n",
       "...                       ...                          ...   \n",
       "2292                  582.600                     0.841459   \n",
       "901                   518.200                     0.762954   \n",
       "1166                  417.875                     0.706425   \n",
       "1289                  493.400                     0.770045   \n",
       "2532                  279.000                     0.605735   \n",
       "\n",
       "      shot_on_target_away_last_10  shot_goal_away_last_10  \\\n",
       "1987                        8.300                     1.9   \n",
       "1517                        7.600                     1.5   \n",
       "1443                        7.000                     1.5   \n",
       "236                        11.375                     3.5   \n",
       "2294                        6.200                     1.1   \n",
       "...                           ...                     ...   \n",
       "2292                        9.300                     1.2   \n",
       "901                         7.400                     1.5   \n",
       "1166                        5.000                     1.5   \n",
       "1289                        7.500                     0.8   \n",
       "2532                        1.000                     0.0   \n",
       "\n",
       "      shot_xg_away_last_10  shot_total_away_last_10  \\\n",
       "1987              1.703411                   14.500   \n",
       "1517              1.380306                   12.800   \n",
       "1443              1.177469                   12.200   \n",
       "236               2.940361                   19.000   \n",
       "2294              1.006067                   11.800   \n",
       "...                    ...                      ...   \n",
       "2292              1.760585                   18.200   \n",
       "901               1.457520                   13.100   \n",
       "1166              0.984060                    9.375   \n",
       "1289              1.037309                   12.000   \n",
       "2532              0.117022                    5.000   \n",
       "\n",
       "      shot_precision_away_last_10  shot_conversion_away_last_10  \n",
       "1987                     0.595837                      0.137152  \n",
       "1517                     0.601868                      0.128652  \n",
       "1443                     0.570802                      0.137092  \n",
       "236                      0.594374                      0.195640  \n",
       "2294                     0.539160                      0.100443  \n",
       "...                           ...                           ...  \n",
       "2292                     0.504216                      0.069941  \n",
       "901                      0.562998                      0.116797  \n",
       "1166                     0.550496                      0.144494  \n",
       "1289                     0.596746                      0.097073  \n",
       "2532                     0.200000                      0.000000  \n",
       "\n",
       "[1703 rows x 36 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, penalty=l2;, score=0.399 total time=   0.3s[CV 3/5] END alpha=0.0001, loss=hinge, penalty=l2;, score=0.328 total time=   0.3s\n",
      "\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, penalty=l2;, score=0.276 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, penalty=l2;, score=0.444 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, penalty=l1;, score=0.429 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, penalty=elasticnet;, score=0.487 total time=   0.5s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, penalty=l1;, score=0.376 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, penalty=l1;, score=0.431 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, penalty=elasticnet;, score=0.440 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, penalty=elasticnet;, score=0.481 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, penalty=elasticnet;, score=0.291 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, penalty=None;, score=0.513 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, penalty=None;, score=0.496 total time=   0.2s[CV 4/5] END alpha=0.0001, loss=hinge, penalty=l2;, score=0.397 total time=   0.3s\n",
      "\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, penalty=None;, score=0.490 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, penalty=None;, score=0.482 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, penalty=None;, score=0.362 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, penalty=elasticnet;, score=0.462 total time=   0.7s\n",
      "[CV 2/5] END alpha=0.0001, loss=squared_hinge, penalty=l2;, score=0.255 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=squared_hinge, penalty=l2;, score=0.455 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=squared_hinge, penalty=l2;, score=0.399 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=squared_hinge, penalty=l2;, score=0.459 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=squared_hinge, penalty=l2;, score=0.344 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, penalty=l1;, score=0.472 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.0001, loss=squared_hinge, penalty=l1;, score=0.460 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.0001, loss=squared_hinge, penalty=l1;, score=0.487 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.0001, loss=squared_hinge, penalty=l1;, score=0.425 total time=   0.6s\n",
      "[CV 4/5] END alpha=0.0001, loss=squared_hinge, penalty=l1;, score=0.465 total time=   0.5s\n",
      "[CV 5/5] END alpha=0.0001, loss=squared_hinge, penalty=l1;, score=0.447 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=squared_hinge, penalty=elasticnet;, score=0.328 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.0001, loss=squared_hinge, penalty=None;, score=0.361 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=squared_hinge, penalty=None;, score=0.434 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=squared_hinge, penalty=elasticnet;, score=0.440 total time=   0.6s\n",
      "[CV 4/5] END alpha=0.0001, loss=squared_hinge, penalty=elasticnet;, score=0.485 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, penalty=l1;, score=0.261 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0001, loss=squared_hinge, penalty=None;, score=0.326 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=squared_hinge, penalty=None;, score=0.494 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=squared_hinge, penalty=None;, score=0.503 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=squared_hinge, penalty=elasticnet;, score=0.500 total time=   0.6s\n",
      "[CV 1/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.282 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=squared_hinge, penalty=elasticnet;, score=0.364 total time=   0.7s\n",
      "[CV 2/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.326 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.452 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.247 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.344 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.469 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.384 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.418 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.372 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.497 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=modified_huber, penalty=elasticnet;, score=0.490 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=modified_huber, penalty=elasticnet;, score=0.449 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=modified_huber, penalty=None;, score=0.487 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=modified_huber, penalty=elasticnet;, score=0.308 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.0001, loss=modified_huber, penalty=None;, score=0.525 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=modified_huber, penalty=None;, score=0.449 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=modified_huber, penalty=None;, score=0.326 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=modified_huber, penalty=elasticnet;, score=0.482 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.001, loss=hinge, penalty=l2;, score=0.422 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=modified_huber, penalty=None;, score=0.282 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.001, loss=hinge, penalty=l2;, score=0.446 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.0001, loss=modified_huber, penalty=elasticnet;, score=0.353 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.001, loss=hinge, penalty=l2;, score=0.446 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.001, loss=hinge, penalty=l2;, score=0.479 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.001, loss=hinge, penalty=l2;, score=0.432 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.001, loss=hinge, penalty=l1;, score=0.478 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.001, loss=hinge, penalty=l1;, score=0.425 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.001, loss=hinge, penalty=l1;, score=0.370 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.001, loss=hinge, penalty=l1;, score=0.468 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.001, loss=hinge, penalty=l1;, score=0.465 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.001, loss=hinge, penalty=None;, score=0.378 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.001, loss=hinge, penalty=elasticnet;, score=0.443 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.001, loss=hinge, penalty=elasticnet;, score=0.255 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.001, loss=hinge, penalty=elasticnet;, score=0.481 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.001, loss=hinge, penalty=None;, score=0.499 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.001, loss=hinge, penalty=elasticnet;, score=0.388 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.001, loss=hinge, penalty=elasticnet;, score=0.315 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.001, loss=hinge, penalty=None;, score=0.453 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.001, loss=hinge, penalty=None;, score=0.466 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.001, loss=hinge, penalty=None;, score=0.397 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.001, loss=squared_hinge, penalty=l2;, score=0.378 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.001, loss=squared_hinge, penalty=l2;, score=0.402 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.001, loss=squared_hinge, penalty=l2;, score=0.255 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.001, loss=squared_hinge, penalty=l2;, score=0.429 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.001, loss=squared_hinge, penalty=l2;, score=0.441 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.001, loss=squared_hinge, penalty=l1;, score=0.352 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.001, loss=squared_hinge, penalty=l1;, score=0.516 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.001, loss=squared_hinge, penalty=l1;, score=0.294 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.001, loss=squared_hinge, penalty=l1;, score=0.402 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.001, loss=squared_hinge, penalty=l1;, score=0.315 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.001, loss=squared_hinge, penalty=None;, score=0.463 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.001, loss=squared_hinge, penalty=None;, score=0.416 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.001, loss=squared_hinge, penalty=elasticnet;, score=0.326 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.001, loss=squared_hinge, penalty=None;, score=0.413 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.001, loss=squared_hinge, penalty=elasticnet;, score=0.499 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.001, loss=squared_hinge, penalty=elasticnet;, score=0.255 total time=   0.6s\n",
      "[CV 2/5] END alpha=0.001, loss=modified_huber, penalty=l2;, score=0.504 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.001, loss=squared_hinge, penalty=elasticnet;, score=0.288 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.001, loss=squared_hinge, penalty=None;, score=0.503 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.001, loss=modified_huber, penalty=l2;, score=0.402 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.001, loss=squared_hinge, penalty=None;, score=0.335 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.001, loss=squared_hinge, penalty=elasticnet;, score=0.491 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.001, loss=modified_huber, penalty=l2;, score=0.331 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.001, loss=modified_huber, penalty=l2;, score=0.450 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.001, loss=modified_huber, penalty=l2;, score=0.509 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.001, loss=modified_huber, penalty=l1;, score=0.478 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.001, loss=modified_huber, penalty=l1;, score=0.267 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.001, loss=modified_huber, penalty=l1;, score=0.503 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.001, loss=modified_huber, penalty=l1;, score=0.463 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.001, loss=modified_huber, penalty=l1;, score=0.303 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.001, loss=modified_huber, penalty=None;, score=0.455 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.001, loss=modified_huber, penalty=elasticnet;, score=0.252 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.001, loss=modified_huber, penalty=None;, score=0.355 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.001, loss=modified_huber, penalty=elasticnet;, score=0.449 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.001, loss=modified_huber, penalty=None;, score=0.478 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.001, loss=modified_huber, penalty=elasticnet;, score=0.443 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.001, loss=modified_huber, penalty=None;, score=0.506 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.001, loss=modified_huber, penalty=None;, score=0.368 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.001, loss=modified_huber, penalty=elasticnet;, score=0.450 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.001, loss=modified_huber, penalty=elasticnet;, score=0.391 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.01, loss=hinge, penalty=l2;, score=0.434 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.01, loss=hinge, penalty=l2;, score=0.449 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.01, loss=hinge, penalty=l2;, score=0.487 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.01, loss=hinge, penalty=l1;, score=0.499 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.01, loss=hinge, penalty=l1;, score=0.440 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.01, loss=hinge, penalty=l2;, score=0.444 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.01, loss=hinge, penalty=l2;, score=0.315 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.01, loss=hinge, penalty=l1;, score=0.466 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.01, loss=hinge, penalty=elasticnet;, score=0.375 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.01, loss=hinge, penalty=l1;, score=0.459 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.01, loss=hinge, penalty=elasticnet;, score=0.328 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.01, loss=hinge, penalty=l1;, score=0.438 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.01, loss=hinge, penalty=elasticnet;, score=0.444 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.01, loss=hinge, penalty=elasticnet;, score=0.507 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.01, loss=hinge, penalty=None;, score=0.402 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.01, loss=hinge, penalty=None;, score=0.387 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.01, loss=hinge, penalty=None;, score=0.455 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.01, loss=hinge, penalty=elasticnet;, score=0.450 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.01, loss=hinge, penalty=None;, score=0.400 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.01, loss=hinge, penalty=None;, score=0.418 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.01, loss=squared_hinge, penalty=l2;, score=0.452 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.01, loss=squared_hinge, penalty=l2;, score=0.471 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.01, loss=squared_hinge, penalty=l2;, score=0.499 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.01, loss=squared_hinge, penalty=l2;, score=0.437 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.01, loss=squared_hinge, penalty=l2;, score=0.447 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.01, loss=squared_hinge, penalty=l1;, score=0.468 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.01, loss=squared_hinge, penalty=l1;, score=0.302 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.01, loss=squared_hinge, penalty=l1;, score=0.472 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.01, loss=squared_hinge, penalty=elasticnet;, score=0.434 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.01, loss=squared_hinge, penalty=l1;, score=0.468 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.01, loss=squared_hinge, penalty=elasticnet;, score=0.510 total time=   0.6s\n",
      "[CV 2/5] END alpha=0.01, loss=squared_hinge, penalty=None;, score=0.452 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.01, loss=squared_hinge, penalty=None;, score=0.455 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.01, loss=squared_hinge, penalty=None;, score=0.378 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.01, loss=squared_hinge, penalty=l1;, score=0.308 total time=   0.8s\n",
      "[CV 3/5] END alpha=0.01, loss=squared_hinge, penalty=elasticnet;, score=0.328 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.01, loss=squared_hinge, penalty=None;, score=0.371 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.01, loss=squared_hinge, penalty=None;, score=0.465 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.01, loss=modified_huber, penalty=l2;, score=0.443 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.01, loss=modified_huber, penalty=l2;, score=0.457 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.01, loss=modified_huber, penalty=l2;, score=0.282 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.01, loss=squared_hinge, penalty=elasticnet;, score=0.488 total time=   0.6s\n",
      "[CV 4/5] END alpha=0.01, loss=modified_huber, penalty=l2;, score=0.356 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.01, loss=modified_huber, penalty=l2;, score=0.399 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.01, loss=squared_hinge, penalty=elasticnet;, score=0.497 total time=   0.7s\n",
      "[CV 2/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.405 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.273 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.457 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.01, loss=modified_huber, penalty=None;, score=0.434 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.268 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.01, loss=modified_huber, penalty=elasticnet;, score=0.252 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.500 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.01, loss=modified_huber, penalty=elasticnet;, score=0.255 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.01, loss=modified_huber, penalty=elasticnet;, score=0.453 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.01, loss=modified_huber, penalty=elasticnet;, score=0.311 total time=   0.5s\n",
      "[CV 5/5] END alpha=0.01, loss=modified_huber, penalty=elasticnet;, score=0.479 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.01, loss=modified_huber, penalty=None;, score=0.431 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.01, loss=modified_huber, penalty=None;, score=0.344 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.01, loss=modified_huber, penalty=None;, score=0.444 total time=   0.2s\n",
      "[CV 2/5] END .alpha=0.1, loss=hinge, penalty=l2;, score=0.378 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.01, loss=modified_huber, penalty=None;, score=0.463 total time=   0.3s\n",
      "[CV 4/5] END .alpha=0.1, loss=hinge, penalty=l2;, score=0.262 total time=   0.1s\n",
      "[CV 1/5] END .alpha=0.1, loss=hinge, penalty=l2;, score=0.320 total time=   0.3s\n",
      "[CV 5/5] END .alpha=0.1, loss=hinge, penalty=l2;, score=0.312 total time=   0.3s\n",
      "[CV 3/5] END .alpha=0.1, loss=hinge, penalty=l2;, score=0.457 total time=   0.4s\n",
      "[CV 1/5] END .alpha=0.1, loss=hinge, penalty=l1;, score=0.496 total time=   0.4s\n",
      "[CV 3/5] END .alpha=0.1, loss=hinge, penalty=l1;, score=0.364 total time=   0.4s\n",
      "[CV 5/5] END .alpha=0.1, loss=hinge, penalty=l1;, score=0.447 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.1, loss=hinge, penalty=elasticnet;, score=0.425 total time=   0.3s\n",
      "[CV 2/5] END .alpha=0.1, loss=hinge, penalty=l1;, score=0.399 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.1, loss=hinge, penalty=elasticnet;, score=0.528 total time=   0.3s\n",
      "[CV 4/5] END .alpha=0.1, loss=hinge, penalty=l1;, score=0.382 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.1, loss=hinge, penalty=elasticnet;, score=0.329 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.1, loss=hinge, penalty=elasticnet;, score=0.494 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.1, loss=hinge, penalty=None;, score=0.481 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.1, loss=hinge, penalty=elasticnet;, score=0.449 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.1, loss=hinge, penalty=None;, score=0.443 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.1, loss=hinge, penalty=None;, score=0.326 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.1, loss=hinge, penalty=None;, score=0.499 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.1, loss=squared_hinge, penalty=l2;, score=0.334 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.1, loss=squared_hinge, penalty=l2;, score=0.457 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.1, loss=squared_hinge, penalty=l2;, score=0.449 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.1, loss=hinge, penalty=None;, score=0.418 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.1, loss=squared_hinge, penalty=l2;, score=0.332 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.1, loss=squared_hinge, penalty=l2;, score=0.312 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.1, loss=squared_hinge, penalty=l1;, score=0.501 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.1, loss=squared_hinge, penalty=l1;, score=0.491 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.1, loss=squared_hinge, penalty=l1;, score=0.494 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.1, loss=squared_hinge, penalty=l1;, score=0.446 total time=   0.7s\n",
      "[CV 2/5] END alpha=0.1, loss=squared_hinge, penalty=elasticnet;, score=0.528 total time=   0.7s\n",
      "[CV 1/5] END alpha=0.1, loss=squared_hinge, penalty=None;, score=0.481 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.1, loss=squared_hinge, penalty=l1;, score=0.460 total time=   1.0s\n",
      "[CV 1/5] END alpha=0.1, loss=squared_hinge, penalty=elasticnet;, score=0.431 total time=   0.9s\n",
      "[CV 4/5] END alpha=0.1, loss=squared_hinge, penalty=elasticnet;, score=0.509 total time=   0.7s\n",
      "[CV 3/5] END alpha=0.1, loss=squared_hinge, penalty=None;, score=0.428 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.1, loss=squared_hinge, penalty=None;, score=0.409 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.1, loss=squared_hinge, penalty=None;, score=0.510 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.1, loss=squared_hinge, penalty=elasticnet;, score=0.504 total time=   0.9s\n",
      "[CV 5/5] END alpha=0.1, loss=squared_hinge, penalty=None;, score=0.318 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.1, loss=modified_huber, penalty=l2;, score=0.264 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.1, loss=modified_huber, penalty=l2;, score=0.434 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.1, loss=squared_hinge, penalty=elasticnet;, score=0.247 total time=   0.7s\n",
      "[CV 1/5] END alpha=0.1, loss=modified_huber, penalty=l2;, score=0.290 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.1, loss=modified_huber, penalty=l2;, score=0.421 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.1, loss=modified_huber, penalty=l2;, score=0.503 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.1, loss=modified_huber, penalty=elasticnet;, score=0.493 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.1, loss=modified_huber, penalty=l1;, score=0.429 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.1, loss=modified_huber, penalty=elasticnet;, score=0.378 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.1, loss=modified_huber, penalty=l1;, score=0.494 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.1, loss=modified_huber, penalty=l1;, score=0.308 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.1, loss=modified_huber, penalty=elasticnet;, score=0.466 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.1, loss=modified_huber, penalty=None;, score=0.457 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.1, loss=modified_huber, penalty=l1;, score=0.490 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.1, loss=modified_huber, penalty=l1;, score=0.513 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.1, loss=modified_huber, penalty=None;, score=0.515 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.1, loss=modified_huber, penalty=None;, score=0.337 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.1, loss=modified_huber, penalty=elasticnet;, score=0.456 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.1, loss=modified_huber, penalty=None;, score=0.499 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.1, loss=modified_huber, penalty=elasticnet;, score=0.447 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.1, loss=modified_huber, penalty=None;, score=0.444 total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SGDClassifier(max_iter=10000), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1],\n",
       "                         &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;squared_hinge&#x27;, &#x27;modified_huber&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;, None]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SGDClassifier(max_iter=10000), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1],\n",
       "                         &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;squared_hinge&#x27;, &#x27;modified_huber&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;, None]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(max_iter=10000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(max_iter=10000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SGDClassifier(max_iter=10000), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
       "                         'loss': ['hinge', 'squared_hinge', 'modified_huber'],\n",
       "                         'penalty': ['l2', 'l1', 'elasticnet', None]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"loss\" : [\"hinge\", \"squared_hinge\", \"modified_huber\"],\n",
    "    \"alpha\" : [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"penalty\" : [\"l2\", \"l1\", \"elasticnet\", None],\n",
    "}\n",
    "clf = SGDClassifier(max_iter=10000)\n",
    "grid = GridSearchCV(clf, param_grid=params, cv=5, n_jobs = -1, scoring='accuracy', verbose=3)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'alpha': 0.1, 'loss': 'squared_hinge', 'penalty': 'l1'}, 0.4785837502156288)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_, grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3283173734610123\n",
      "{'alpha': 0.1, 'loss': 'squared_hinge', 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(np.zeros((1,36)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RobustScaler()\n",
    "X_train_rob = rs.fit_transform(X_train)\n",
    "X_test_rob = rs.transform(X_test)\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "X_train_mm = mms.fit_transform(X_train)\n",
    "X_test_mm = mms.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END ...............alpha=0.0001, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END ...............alpha=0.0001, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END ...............alpha=0.0001, loss=hinge, penalty=l2; total time=   0.2s\n",
      "[CV] END ...............alpha=0.0001, loss=hinge, penalty=l1; total time=   0.2s\n",
      "[CV] END ...............alpha=0.0001, loss=hinge, penalty=l1; total time=   0.2s\n",
      "[CV] END .......alpha=0.0001, loss=hinge, penalty=elasticnet; total time=   0.5s\n",
      "[CV] END .......alpha=0.0001, loss=hinge, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END .......alpha=0.0001, loss=hinge, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END .............alpha=0.0001, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END .......alpha=0.0001, loss=hinge, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END .............alpha=0.0001, loss=hinge, penalty=None; total time=   0.2s\n",
      "[CV] END .......alpha=0.0001, loss=hinge, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END .............alpha=0.0001, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END .............alpha=0.0001, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END .......alpha=0.0001, loss=squared_hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END ...............alpha=0.0001, loss=hinge, penalty=l2; total time=   0.2s\n",
      "[CV] END .............alpha=0.0001, loss=hinge, penalty=None; total time=   0.2s\n",
      "[CV] END .......alpha=0.0001, loss=squared_hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END .......alpha=0.0001, loss=squared_hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END .......alpha=0.0001, loss=squared_hinge, penalty=l2; total time=   0.2s\n",
      "[CV] END .......alpha=0.0001, loss=squared_hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END .......alpha=0.0001, loss=squared_hinge, penalty=l1; total time=   0.3s\n",
      "[CV] END .......alpha=0.0001, loss=squared_hinge, penalty=l1; total time=   0.3s\n",
      "[CV] END .......alpha=0.0001, loss=squared_hinge, penalty=l1; total time=   0.3s\n",
      "[CV] END .......alpha=0.0001, loss=squared_hinge, penalty=l1; total time=   0.4s\n",
      "[CV] END .......alpha=0.0001, loss=squared_hinge, penalty=l1; total time=   0.2s\n",
      "[CV] END ...............alpha=0.0001, loss=hinge, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END .....alpha=0.0001, loss=squared_hinge, penalty=None; total time=   0.1s\n",
      "[CV] END .....alpha=0.0001, loss=squared_hinge, penalty=None; total time=   0.1s\n",
      "[CV] END .....alpha=0.0001, loss=squared_hinge, penalty=None; total time=   0.2s\n",
      "[CV] END .....alpha=0.0001, loss=squared_hinge, penalty=None; total time=   0.1s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END .....alpha=0.0001, loss=squared_hinge, penalty=None; total time=   0.2s\n",
      "[CV] END ......alpha=0.0001, loss=modified_huber, penalty=l2; total time=   0.2s\n",
      "[CV] END ......alpha=0.0001, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END ......alpha=0.0001, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END ......alpha=0.0001, loss=modified_huber, penalty=l2; total time=   0.2s\n",
      "[CV] END ......alpha=0.0001, loss=modified_huber, penalty=l2; total time=   0.2s\n",
      "[CV] END ......alpha=0.0001, loss=modified_huber, penalty=l1; total time=   0.2s\n",
      "[CV] END ......alpha=0.0001, loss=modified_huber, penalty=l1; total time=   0.3s\n",
      "[CV] END ......alpha=0.0001, loss=modified_huber, penalty=l1; total time=   0.3s\n",
      "[CV] END ......alpha=0.0001, loss=modified_huber, penalty=l1; total time=   0.3s\n",
      "[CV] END ...............alpha=0.0001, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END ......alpha=0.0001, loss=modified_huber, penalty=l1; total time=   0.4s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END ....alpha=0.0001, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END ....alpha=0.0001, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END ....alpha=0.0001, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END ................alpha=0.001, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END ....alpha=0.0001, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END ....alpha=0.0001, loss=modified_huber, penalty=None; total time=   0.2s\n",
      "[CV] END ................alpha=0.001, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END ................alpha=0.001, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END ................alpha=0.001, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END ................alpha=0.001, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, penalty=elasticnet; total time=   0.5s\n",
      "[CV] END ................alpha=0.001, loss=hinge, penalty=l1; total time=   0.2s[CV] END ................alpha=0.001, loss=hinge, penalty=l1; total time=   0.2s\n",
      "\n",
      "[CV] END ................alpha=0.001, loss=hinge, penalty=l1; total time=   0.2s\n",
      "[CV] END ................alpha=0.001, loss=hinge, penalty=l1; total time=   0.3s\n",
      "[CV] END ................alpha=0.001, loss=hinge, penalty=l1; total time=   0.2s\n",
      "[CV] END ...............alpha=0.0001, loss=hinge, penalty=l1; total time=   0.4s\n",
      "[CV] END ..............alpha=0.001, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ...............alpha=0.0001, loss=hinge, penalty=l1; total time=   0.4s\n",
      "[CV] END ........alpha=0.001, loss=hinge, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END ........alpha=0.001, loss=hinge, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END ........alpha=0.001, loss=hinge, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END ..............alpha=0.001, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ..............alpha=0.001, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ..............alpha=0.001, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ..............alpha=0.001, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ........alpha=0.001, loss=hinge, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END ........alpha=0.001, loss=squared_hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END ........alpha=0.001, loss=squared_hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END ........alpha=0.001, loss=hinge, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END ........alpha=0.001, loss=squared_hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END ........alpha=0.001, loss=squared_hinge, penalty=l2; total time=   0.2s\n",
      "[CV] END ........alpha=0.001, loss=squared_hinge, penalty=l1; total time=   0.2s\n",
      "[CV] END ........alpha=0.001, loss=squared_hinge, penalty=l1; total time=   0.3s[CV] END alpha=0.001, loss=squared_hinge, penalty=elasticnet; total time=   0.2s\n",
      "\n",
      "[CV] END ........alpha=0.001, loss=squared_hinge, penalty=l1; total time=   0.2s\n",
      "[CV] END ........alpha=0.001, loss=squared_hinge, penalty=l1; total time=   0.2s\n",
      "[CV] END ......alpha=0.001, loss=squared_hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ........alpha=0.001, loss=squared_hinge, penalty=l2; total time=   0.5s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END ......alpha=0.001, loss=squared_hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ......alpha=0.001, loss=squared_hinge, penalty=None; total time=   0.1s\n",
      "[CV] END .......alpha=0.001, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END .......alpha=0.001, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END .......alpha=0.001, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END ......alpha=0.001, loss=squared_hinge, penalty=None; total time=   0.2s\n",
      "[CV] END ......alpha=0.001, loss=squared_hinge, penalty=None; total time=   0.2s\n",
      "[CV] END ........alpha=0.001, loss=squared_hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END .......alpha=0.001, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END .......alpha=0.001, loss=modified_huber, penalty=l2; total time=   0.2s\n",
      "[CV] END .......alpha=0.001, loss=modified_huber, penalty=l1; total time=   0.3s\n",
      "[CV] END .......alpha=0.001, loss=modified_huber, penalty=l1; total time=   0.3s\n",
      "[CV] END .......alpha=0.001, loss=modified_huber, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.001, loss=modified_huber, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END .......alpha=0.001, loss=modified_huber, penalty=l1; total time=   0.4s\n",
      "[CV] END .....alpha=0.001, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END alpha=0.001, loss=modified_huber, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END .......alpha=0.001, loss=modified_huber, penalty=l1; total time=   0.4s\n",
      "[CV] END alpha=0.001, loss=modified_huber, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, loss=modified_huber, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END .....alpha=0.001, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END .................alpha=0.01, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END .....alpha=0.001, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END .....alpha=0.001, loss=modified_huber, penalty=None; total time=   0.2s\n",
      "[CV] END .................alpha=0.01, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END .................alpha=0.01, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END .....alpha=0.001, loss=modified_huber, penalty=None; total time=   0.2s\n",
      "[CV] END .................alpha=0.01, loss=hinge, penalty=l1; total time=   0.1s\n",
      "[CV] END .................alpha=0.01, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END .................alpha=0.01, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END .................alpha=0.01, loss=hinge, penalty=l1; total time=   0.1s\n",
      "[CV] END .................alpha=0.01, loss=hinge, penalty=l1; total time=   0.1s\n",
      "[CV] END .................alpha=0.01, loss=hinge, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, loss=modified_huber, penalty=elasticnet; total time=   0.5s\n",
      "[CV] END .........alpha=0.01, loss=hinge, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END .................alpha=0.01, loss=hinge, penalty=l1; total time=   0.2s\n",
      "[CV] END .........alpha=0.01, loss=hinge, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END .........alpha=0.01, loss=hinge, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END .........alpha=0.01, loss=hinge, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END .........alpha=0.01, loss=hinge, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END ...............alpha=0.01, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ...............alpha=0.01, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ...............alpha=0.01, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ...............alpha=0.01, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ...............alpha=0.01, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, penalty=elasticnet; total time=   1.7s\n",
      "[CV] END .........alpha=0.01, loss=squared_hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END .........alpha=0.01, loss=squared_hinge, penalty=l1; total time=   0.8s\n",
      "[CV] END .........alpha=0.01, loss=squared_hinge, penalty=l1; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........alpha=0.01, loss=squared_hinge, penalty=l1; total time=  10.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........alpha=0.01, loss=squared_hinge, penalty=l2; total time=  12.7s\n",
      "[CV] END .........alpha=0.01, loss=squared_hinge, penalty=l2; total time=  12.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........alpha=0.01, loss=squared_hinge, penalty=l2; total time=  17.5s\n",
      "[CV] END .........alpha=0.01, loss=squared_hinge, penalty=l2; total time=  17.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........alpha=0.01, loss=squared_hinge, penalty=l2; total time=  17.9s\n",
      "[CV] END .......alpha=0.01, loss=squared_hinge, penalty=None; total time=   0.3s\n",
      "[CV] END .......alpha=0.01, loss=squared_hinge, penalty=None; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........alpha=0.01, loss=squared_hinge, penalty=l1; total time=  20.1s\n",
      "[CV] END .......alpha=0.01, loss=squared_hinge, penalty=None; total time=   0.4s\n",
      "[CV] END ........alpha=0.01, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END ........alpha=0.01, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END ........alpha=0.01, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END ........alpha=0.01, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END ........alpha=0.01, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END ........alpha=0.01, loss=modified_huber, penalty=l1; total time=   0.1s\n",
      "[CV] END ........alpha=0.01, loss=modified_huber, penalty=l1; total time=   0.1s\n",
      "[CV] END ........alpha=0.01, loss=modified_huber, penalty=l1; total time=   0.1s\n",
      "[CV] END ........alpha=0.01, loss=modified_huber, penalty=l1; total time=   0.1s\n",
      "[CV] END ........alpha=0.01, loss=modified_huber, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, loss=modified_huber, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, loss=modified_huber, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, loss=modified_huber, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, loss=modified_huber, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, loss=modified_huber, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END ......alpha=0.01, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END ......alpha=0.01, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END ......alpha=0.01, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END ......alpha=0.01, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END ......alpha=0.01, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END ..................alpha=0.1, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, loss=hinge, penalty=l1; total time=   0.1s\n",
      "[CV] END ..................alpha=0.1, loss=hinge, penalty=l1; total time=   0.1s\n",
      "[CV] END ..........alpha=0.1, loss=hinge, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END ..........alpha=0.1, loss=hinge, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END ..........alpha=0.1, loss=hinge, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END ..........alpha=0.1, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ..........alpha=0.1, loss=hinge, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END ................alpha=0.1, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ................alpha=0.1, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ................alpha=0.1, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ................alpha=0.1, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ................alpha=0.1, loss=hinge, penalty=None; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......alpha=0.01, loss=squared_hinge, penalty=None; total time=   7.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......alpha=0.01, loss=squared_hinge, penalty=None; total time=   7.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.1, loss=squared_hinge, penalty=l2; total time=  17.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.01, loss=squared_hinge, penalty=elasticnet; total time=  40.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.1, loss=squared_hinge, penalty=l2; total time=  18.1s\n",
      "[CV] END .alpha=0.01, loss=squared_hinge, penalty=elasticnet; total time=  32.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.1, loss=squared_hinge, penalty=l2; total time=  21.0s\n",
      "[CV] END .alpha=0.01, loss=squared_hinge, penalty=elasticnet; total time=  33.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.01, loss=squared_hinge, penalty=elasticnet; total time=  36.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.1, loss=squared_hinge, penalty=l2; total time=  12.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.1, loss=squared_hinge, penalty=l2; total time=  17.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.01, loss=squared_hinge, penalty=elasticnet; total time=  42.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.1, loss=squared_hinge, penalty=l1; total time=  28.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.1, loss=squared_hinge, penalty=l1; total time=  28.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.1, loss=squared_hinge, penalty=l1; total time=  28.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.1, loss=squared_hinge, penalty=l1; total time=  39.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..alpha=0.1, loss=squared_hinge, penalty=elasticnet; total time=  28.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.1, loss=squared_hinge, penalty=l1; total time=  38.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........alpha=0.1, loss=squared_hinge, penalty=None; total time=  11.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........alpha=0.1, loss=squared_hinge, penalty=None; total time=  12.7s\n",
      "[CV] END .........alpha=0.1, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END .........alpha=0.1, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END .........alpha=0.1, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END .........alpha=0.1, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END .........alpha=0.1, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END ..alpha=0.1, loss=squared_hinge, penalty=elasticnet; total time=  37.4s\n",
      "[CV] END .........alpha=0.1, loss=modified_huber, penalty=l1; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........alpha=0.1, loss=modified_huber, penalty=l1; total time=   0.1s\n",
      "[CV] END .........alpha=0.1, loss=modified_huber, penalty=l1; total time=   0.1s\n",
      "[CV] END .........alpha=0.1, loss=modified_huber, penalty=l1; total time=   0.1s\n",
      "[CV] END .alpha=0.1, loss=modified_huber, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END .........alpha=0.1, loss=modified_huber, penalty=l1; total time=   0.1s\n",
      "[CV] END .alpha=0.1, loss=modified_huber, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END .alpha=0.1, loss=modified_huber, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END .alpha=0.1, loss=modified_huber, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END .......alpha=0.1, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END .alpha=0.1, loss=modified_huber, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END .......alpha=0.1, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END .......alpha=0.1, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END .......alpha=0.1, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END ..alpha=0.1, loss=squared_hinge, penalty=elasticnet; total time=  37.9s\n",
      "[CV] END .......alpha=0.1, loss=modified_huber, penalty=None; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........alpha=0.1, loss=squared_hinge, penalty=None; total time=  15.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........alpha=0.1, loss=squared_hinge, penalty=None; total time=  14.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..alpha=0.1, loss=squared_hinge, penalty=elasticnet; total time=  27.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........alpha=0.1, loss=squared_hinge, penalty=None; total time=  11.4s\n",
      "[CV] END ..alpha=0.1, loss=squared_hinge, penalty=elasticnet; total time=  26.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SGDClassifier(max_iter=10000), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1],\n",
       "                         &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;squared_hinge&#x27;, &#x27;modified_huber&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;, None]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SGDClassifier(max_iter=10000), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1],\n",
       "                         &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;squared_hinge&#x27;, &#x27;modified_huber&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;, None]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(max_iter=10000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(max_iter=10000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SGDClassifier(max_iter=10000), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
       "                         'loss': ['hinge', 'squared_hinge', 'modified_huber'],\n",
       "                         'penalty': ['l2', 'l1', 'elasticnet', None]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rob = GridSearchCV(clf, param_grid=params, cv=5, n_jobs = -1, scoring='accuracy', verbose=2)\n",
    "grid_rob.fit(X_train_rob, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5321477428180574\n",
      "{'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "y_pred_rob = grid_rob.predict(X_test_rob)\n",
    "print(accuracy_score(y_test, y_pred_rob))\n",
    "print(grid_rob.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.30759686, 0.25711524, 0.4352879 ]]), array([-1,  0,  1]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rob.predict_proba(np.zeros((1,36))), grid_rob.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SGDClassifier(max_iter=10000), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1],\n",
       "                         &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;squared_hinge&#x27;, &#x27;modified_huber&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;, None]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SGDClassifier(max_iter=10000), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1],\n",
       "                         &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;squared_hinge&#x27;, &#x27;modified_huber&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;, None]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(max_iter=10000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(max_iter=10000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SGDClassifier(max_iter=10000), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
       "                         'loss': ['hinge', 'squared_hinge', 'modified_huber'],\n",
       "                         'penalty': ['l2', 'l1', 'elasticnet', None]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_mm = GridSearchCV(clf, param_grid=params, cv=5, n_jobs = -1, scoring='accuracy', verbose=1)\n",
    "grid_mm.fit(X_train_mm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5266757865937073\n",
      "{'alpha': 0.1, 'loss': 'hinge', 'penalty': None}\n"
     ]
    }
   ],
   "source": [
    "y_pred_mm = grid_mm.predict(X_test_mm)\n",
    "print(accuracy_score(y_test, y_pred_mm))\n",
    "print(grid_mm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1]), array([-1,  0,  1]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_mm.predict(np.zeros((1,36))), grid_mm.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 12:50:05.225906: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-12 12:50:05.891639: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-12 12:50:05.912665: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-12 12:50:10.183562: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Loading TensorFlow...\u001b[0m\n",
      "\n",
      "✅ TensorFlow loaded (0.0s)\n"
     ]
    }
   ],
   "source": [
    "import goalguru.soccermatch_package.ml_logic.model as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model initialized\n"
     ]
    }
   ],
   "source": [
    "model = sm.initialize_model(X_train_rob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model compiled\n"
     ]
    }
   ],
   "source": [
    "model = sm.compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat = to_categorical(y_train, num_classes=3)\n",
    "y_test_cat = to_categorical(y_test, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Training model...\u001b[0m\n",
      "✅ Model trained on 1703 rows with accuracy: 0.45\n"
     ]
    }
   ],
   "source": [
    "model, history = sm.train_model(model, X_train_rob, y_train_cat, patience=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Evaluating model on 731 rows...\u001b[0m\n",
      "✅ Model evaluated, accuracy: 0.45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 1.0420852899551392, 'accuracy': 0.4487003982067108}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = sm.evaluate_model(model, X_test_rob, y_test_cat)\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goalguru",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
