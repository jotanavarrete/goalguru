{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from goalguru.statsbombs_package.data_processor import load_all_seasons_past_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9_27.csv loaded locally\n",
      "37_90.csv loaded locally\n",
      "37_42.csv loaded locally\n",
      "37_4.csv loaded locally\n",
      "43_106.csv loaded locally\n",
      "43_3.csv loaded locally\n",
      "1238_108.csv loaded locally\n",
      "11_27.csv loaded locally\n",
      "7_27.csv loaded locally\n",
      "2_27.csv loaded locally\n",
      "12_27.csv loaded locally\n",
      "55_43.csv loaded locally\n",
      "72_107.csv loaded locally\n",
      "72_30.csv loaded locally\n",
      "53_106.csv loaded locally\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2590, 38)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = load_all_seasons_past_info(save_concat=False)\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['match_id', 'target', 'pass_completed_home_all_past',\n",
       "       'pass_total_home_all_past', 'pass_precision_home_all_past',\n",
       "       'shot_on_target_home_all_past', 'shot_goal_home_all_past',\n",
       "       'shot_xg_home_all_past', 'shot_total_home_all_past',\n",
       "       'shot_precision_home_all_past', 'shot_conversion_home_all_past',\n",
       "       'pass_completed_home_last_10', 'pass_total_home_last_10',\n",
       "       'pass_precision_home_last_10', 'shot_on_target_home_last_10',\n",
       "       'shot_goal_home_last_10', 'shot_xg_home_last_10',\n",
       "       'shot_total_home_last_10', 'shot_precision_home_last_10',\n",
       "       'shot_conversion_home_last_10', 'pass_completed_away_all_past',\n",
       "       'pass_total_away_all_past', 'pass_precision_away_all_past',\n",
       "       'shot_on_target_away_all_past', 'shot_goal_away_all_past',\n",
       "       'shot_xg_away_all_past', 'shot_total_away_all_past',\n",
       "       'shot_precision_away_all_past', 'shot_conversion_away_all_past',\n",
       "       'pass_completed_away_last_10', 'pass_total_away_last_10',\n",
       "       'pass_precision_away_last_10', 'shot_on_target_away_last_10',\n",
       "       'shot_goal_away_last_10', 'shot_xg_away_last_10',\n",
       "       'shot_total_away_last_10', 'shot_precision_away_last_10',\n",
       "       'shot_conversion_away_last_10'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2434, 36), (2434,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_not_na = all_data.dropna(axis=0, how='any')\n",
    "X = all_data_not_na.drop(columns=['match_id', 'target'])\n",
    "y = all_data_not_na['target']\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, penalty=l2;, score=0.399 total time=   0.3s[CV 3/5] END alpha=0.0001, loss=hinge, penalty=l2;, score=0.328 total time=   0.3s\n",
      "\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, penalty=l2;, score=0.276 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, penalty=l2;, score=0.444 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, penalty=l1;, score=0.429 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, penalty=elasticnet;, score=0.487 total time=   0.5s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, penalty=l1;, score=0.376 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, penalty=l1;, score=0.431 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, penalty=elasticnet;, score=0.440 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, penalty=elasticnet;, score=0.481 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, penalty=elasticnet;, score=0.291 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, penalty=None;, score=0.513 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, penalty=None;, score=0.496 total time=   0.2s[CV 4/5] END alpha=0.0001, loss=hinge, penalty=l2;, score=0.397 total time=   0.3s\n",
      "\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, penalty=None;, score=0.490 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, penalty=None;, score=0.482 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, penalty=None;, score=0.362 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, penalty=elasticnet;, score=0.462 total time=   0.7s\n",
      "[CV 2/5] END alpha=0.0001, loss=squared_hinge, penalty=l2;, score=0.255 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=squared_hinge, penalty=l2;, score=0.455 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=squared_hinge, penalty=l2;, score=0.399 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=squared_hinge, penalty=l2;, score=0.459 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=squared_hinge, penalty=l2;, score=0.344 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, penalty=l1;, score=0.472 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.0001, loss=squared_hinge, penalty=l1;, score=0.460 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.0001, loss=squared_hinge, penalty=l1;, score=0.487 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.0001, loss=squared_hinge, penalty=l1;, score=0.425 total time=   0.6s\n",
      "[CV 4/5] END alpha=0.0001, loss=squared_hinge, penalty=l1;, score=0.465 total time=   0.5s\n",
      "[CV 5/5] END alpha=0.0001, loss=squared_hinge, penalty=l1;, score=0.447 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=squared_hinge, penalty=elasticnet;, score=0.328 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.0001, loss=squared_hinge, penalty=None;, score=0.361 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=squared_hinge, penalty=None;, score=0.434 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=squared_hinge, penalty=elasticnet;, score=0.440 total time=   0.6s\n",
      "[CV 4/5] END alpha=0.0001, loss=squared_hinge, penalty=elasticnet;, score=0.485 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, penalty=l1;, score=0.261 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0001, loss=squared_hinge, penalty=None;, score=0.326 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=squared_hinge, penalty=None;, score=0.494 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=squared_hinge, penalty=None;, score=0.503 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=squared_hinge, penalty=elasticnet;, score=0.500 total time=   0.6s\n",
      "[CV 1/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.282 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=squared_hinge, penalty=elasticnet;, score=0.364 total time=   0.7s\n",
      "[CV 2/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.326 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.452 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.247 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.344 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.469 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.384 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.418 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.372 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.497 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=modified_huber, penalty=elasticnet;, score=0.490 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=modified_huber, penalty=elasticnet;, score=0.449 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=modified_huber, penalty=None;, score=0.487 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=modified_huber, penalty=elasticnet;, score=0.308 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.0001, loss=modified_huber, penalty=None;, score=0.525 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=modified_huber, penalty=None;, score=0.449 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=modified_huber, penalty=None;, score=0.326 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=modified_huber, penalty=elasticnet;, score=0.482 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.001, loss=hinge, penalty=l2;, score=0.422 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=modified_huber, penalty=None;, score=0.282 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.001, loss=hinge, penalty=l2;, score=0.446 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.0001, loss=modified_huber, penalty=elasticnet;, score=0.353 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.001, loss=hinge, penalty=l2;, score=0.446 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.001, loss=hinge, penalty=l2;, score=0.479 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.001, loss=hinge, penalty=l2;, score=0.432 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.001, loss=hinge, penalty=l1;, score=0.478 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.001, loss=hinge, penalty=l1;, score=0.425 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.001, loss=hinge, penalty=l1;, score=0.370 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.001, loss=hinge, penalty=l1;, score=0.468 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.001, loss=hinge, penalty=l1;, score=0.465 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.001, loss=hinge, penalty=None;, score=0.378 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.001, loss=hinge, penalty=elasticnet;, score=0.443 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.001, loss=hinge, penalty=elasticnet;, score=0.255 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.001, loss=hinge, penalty=elasticnet;, score=0.481 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.001, loss=hinge, penalty=None;, score=0.499 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.001, loss=hinge, penalty=elasticnet;, score=0.388 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.001, loss=hinge, penalty=elasticnet;, score=0.315 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.001, loss=hinge, penalty=None;, score=0.453 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.001, loss=hinge, penalty=None;, score=0.466 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.001, loss=hinge, penalty=None;, score=0.397 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.001, loss=squared_hinge, penalty=l2;, score=0.378 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.001, loss=squared_hinge, penalty=l2;, score=0.402 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.001, loss=squared_hinge, penalty=l2;, score=0.255 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.001, loss=squared_hinge, penalty=l2;, score=0.429 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.001, loss=squared_hinge, penalty=l2;, score=0.441 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.001, loss=squared_hinge, penalty=l1;, score=0.352 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.001, loss=squared_hinge, penalty=l1;, score=0.516 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.001, loss=squared_hinge, penalty=l1;, score=0.294 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.001, loss=squared_hinge, penalty=l1;, score=0.402 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.001, loss=squared_hinge, penalty=l1;, score=0.315 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.001, loss=squared_hinge, penalty=None;, score=0.463 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.001, loss=squared_hinge, penalty=None;, score=0.416 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.001, loss=squared_hinge, penalty=elasticnet;, score=0.326 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.001, loss=squared_hinge, penalty=None;, score=0.413 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.001, loss=squared_hinge, penalty=elasticnet;, score=0.499 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.001, loss=squared_hinge, penalty=elasticnet;, score=0.255 total time=   0.6s\n",
      "[CV 2/5] END alpha=0.001, loss=modified_huber, penalty=l2;, score=0.504 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.001, loss=squared_hinge, penalty=elasticnet;, score=0.288 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.001, loss=squared_hinge, penalty=None;, score=0.503 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.001, loss=modified_huber, penalty=l2;, score=0.402 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.001, loss=squared_hinge, penalty=None;, score=0.335 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.001, loss=squared_hinge, penalty=elasticnet;, score=0.491 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.001, loss=modified_huber, penalty=l2;, score=0.331 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.001, loss=modified_huber, penalty=l2;, score=0.450 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.001, loss=modified_huber, penalty=l2;, score=0.509 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.001, loss=modified_huber, penalty=l1;, score=0.478 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.001, loss=modified_huber, penalty=l1;, score=0.267 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.001, loss=modified_huber, penalty=l1;, score=0.503 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.001, loss=modified_huber, penalty=l1;, score=0.463 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.001, loss=modified_huber, penalty=l1;, score=0.303 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.001, loss=modified_huber, penalty=None;, score=0.455 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.001, loss=modified_huber, penalty=elasticnet;, score=0.252 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.001, loss=modified_huber, penalty=None;, score=0.355 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.001, loss=modified_huber, penalty=elasticnet;, score=0.449 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.001, loss=modified_huber, penalty=None;, score=0.478 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.001, loss=modified_huber, penalty=elasticnet;, score=0.443 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.001, loss=modified_huber, penalty=None;, score=0.506 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.001, loss=modified_huber, penalty=None;, score=0.368 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.001, loss=modified_huber, penalty=elasticnet;, score=0.450 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.001, loss=modified_huber, penalty=elasticnet;, score=0.391 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.01, loss=hinge, penalty=l2;, score=0.434 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.01, loss=hinge, penalty=l2;, score=0.449 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.01, loss=hinge, penalty=l2;, score=0.487 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.01, loss=hinge, penalty=l1;, score=0.499 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.01, loss=hinge, penalty=l1;, score=0.440 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.01, loss=hinge, penalty=l2;, score=0.444 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.01, loss=hinge, penalty=l2;, score=0.315 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.01, loss=hinge, penalty=l1;, score=0.466 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.01, loss=hinge, penalty=elasticnet;, score=0.375 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.01, loss=hinge, penalty=l1;, score=0.459 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.01, loss=hinge, penalty=elasticnet;, score=0.328 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.01, loss=hinge, penalty=l1;, score=0.438 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.01, loss=hinge, penalty=elasticnet;, score=0.444 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.01, loss=hinge, penalty=elasticnet;, score=0.507 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.01, loss=hinge, penalty=None;, score=0.402 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.01, loss=hinge, penalty=None;, score=0.387 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.01, loss=hinge, penalty=None;, score=0.455 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.01, loss=hinge, penalty=elasticnet;, score=0.450 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.01, loss=hinge, penalty=None;, score=0.400 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.01, loss=hinge, penalty=None;, score=0.418 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.01, loss=squared_hinge, penalty=l2;, score=0.452 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.01, loss=squared_hinge, penalty=l2;, score=0.471 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.01, loss=squared_hinge, penalty=l2;, score=0.499 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.01, loss=squared_hinge, penalty=l2;, score=0.437 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.01, loss=squared_hinge, penalty=l2;, score=0.447 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.01, loss=squared_hinge, penalty=l1;, score=0.468 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.01, loss=squared_hinge, penalty=l1;, score=0.302 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.01, loss=squared_hinge, penalty=l1;, score=0.472 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.01, loss=squared_hinge, penalty=elasticnet;, score=0.434 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.01, loss=squared_hinge, penalty=l1;, score=0.468 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.01, loss=squared_hinge, penalty=elasticnet;, score=0.510 total time=   0.6s\n",
      "[CV 2/5] END alpha=0.01, loss=squared_hinge, penalty=None;, score=0.452 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.01, loss=squared_hinge, penalty=None;, score=0.455 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.01, loss=squared_hinge, penalty=None;, score=0.378 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.01, loss=squared_hinge, penalty=l1;, score=0.308 total time=   0.8s\n",
      "[CV 3/5] END alpha=0.01, loss=squared_hinge, penalty=elasticnet;, score=0.328 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.01, loss=squared_hinge, penalty=None;, score=0.371 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.01, loss=squared_hinge, penalty=None;, score=0.465 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.01, loss=modified_huber, penalty=l2;, score=0.443 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.01, loss=modified_huber, penalty=l2;, score=0.457 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.01, loss=modified_huber, penalty=l2;, score=0.282 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.01, loss=squared_hinge, penalty=elasticnet;, score=0.488 total time=   0.6s\n",
      "[CV 4/5] END alpha=0.01, loss=modified_huber, penalty=l2;, score=0.356 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.01, loss=modified_huber, penalty=l2;, score=0.399 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.01, loss=squared_hinge, penalty=elasticnet;, score=0.497 total time=   0.7s\n",
      "[CV 2/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.405 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.273 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.457 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.01, loss=modified_huber, penalty=None;, score=0.434 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.268 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.01, loss=modified_huber, penalty=elasticnet;, score=0.252 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.500 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.01, loss=modified_huber, penalty=elasticnet;, score=0.255 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.01, loss=modified_huber, penalty=elasticnet;, score=0.453 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.01, loss=modified_huber, penalty=elasticnet;, score=0.311 total time=   0.5s\n",
      "[CV 5/5] END alpha=0.01, loss=modified_huber, penalty=elasticnet;, score=0.479 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.01, loss=modified_huber, penalty=None;, score=0.431 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.01, loss=modified_huber, penalty=None;, score=0.344 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.01, loss=modified_huber, penalty=None;, score=0.444 total time=   0.2s\n",
      "[CV 2/5] END .alpha=0.1, loss=hinge, penalty=l2;, score=0.378 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.01, loss=modified_huber, penalty=None;, score=0.463 total time=   0.3s\n",
      "[CV 4/5] END .alpha=0.1, loss=hinge, penalty=l2;, score=0.262 total time=   0.1s\n",
      "[CV 1/5] END .alpha=0.1, loss=hinge, penalty=l2;, score=0.320 total time=   0.3s\n",
      "[CV 5/5] END .alpha=0.1, loss=hinge, penalty=l2;, score=0.312 total time=   0.3s\n",
      "[CV 3/5] END .alpha=0.1, loss=hinge, penalty=l2;, score=0.457 total time=   0.4s\n",
      "[CV 1/5] END .alpha=0.1, loss=hinge, penalty=l1;, score=0.496 total time=   0.4s\n",
      "[CV 3/5] END .alpha=0.1, loss=hinge, penalty=l1;, score=0.364 total time=   0.4s\n",
      "[CV 5/5] END .alpha=0.1, loss=hinge, penalty=l1;, score=0.447 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.1, loss=hinge, penalty=elasticnet;, score=0.425 total time=   0.3s\n",
      "[CV 2/5] END .alpha=0.1, loss=hinge, penalty=l1;, score=0.399 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.1, loss=hinge, penalty=elasticnet;, score=0.528 total time=   0.3s\n",
      "[CV 4/5] END .alpha=0.1, loss=hinge, penalty=l1;, score=0.382 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.1, loss=hinge, penalty=elasticnet;, score=0.329 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.1, loss=hinge, penalty=elasticnet;, score=0.494 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.1, loss=hinge, penalty=None;, score=0.481 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.1, loss=hinge, penalty=elasticnet;, score=0.449 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.1, loss=hinge, penalty=None;, score=0.443 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.1, loss=hinge, penalty=None;, score=0.326 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.1, loss=hinge, penalty=None;, score=0.499 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.1, loss=squared_hinge, penalty=l2;, score=0.334 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.1, loss=squared_hinge, penalty=l2;, score=0.457 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.1, loss=squared_hinge, penalty=l2;, score=0.449 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.1, loss=hinge, penalty=None;, score=0.418 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.1, loss=squared_hinge, penalty=l2;, score=0.332 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.1, loss=squared_hinge, penalty=l2;, score=0.312 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.1, loss=squared_hinge, penalty=l1;, score=0.501 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.1, loss=squared_hinge, penalty=l1;, score=0.491 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.1, loss=squared_hinge, penalty=l1;, score=0.494 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.1, loss=squared_hinge, penalty=l1;, score=0.446 total time=   0.7s\n",
      "[CV 2/5] END alpha=0.1, loss=squared_hinge, penalty=elasticnet;, score=0.528 total time=   0.7s\n",
      "[CV 1/5] END alpha=0.1, loss=squared_hinge, penalty=None;, score=0.481 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.1, loss=squared_hinge, penalty=l1;, score=0.460 total time=   1.0s\n",
      "[CV 1/5] END alpha=0.1, loss=squared_hinge, penalty=elasticnet;, score=0.431 total time=   0.9s\n",
      "[CV 4/5] END alpha=0.1, loss=squared_hinge, penalty=elasticnet;, score=0.509 total time=   0.7s\n",
      "[CV 3/5] END alpha=0.1, loss=squared_hinge, penalty=None;, score=0.428 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.1, loss=squared_hinge, penalty=None;, score=0.409 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.1, loss=squared_hinge, penalty=None;, score=0.510 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.1, loss=squared_hinge, penalty=elasticnet;, score=0.504 total time=   0.9s\n",
      "[CV 5/5] END alpha=0.1, loss=squared_hinge, penalty=None;, score=0.318 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.1, loss=modified_huber, penalty=l2;, score=0.264 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.1, loss=modified_huber, penalty=l2;, score=0.434 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.1, loss=squared_hinge, penalty=elasticnet;, score=0.247 total time=   0.7s\n",
      "[CV 1/5] END alpha=0.1, loss=modified_huber, penalty=l2;, score=0.290 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.1, loss=modified_huber, penalty=l2;, score=0.421 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.1, loss=modified_huber, penalty=l2;, score=0.503 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.1, loss=modified_huber, penalty=elasticnet;, score=0.493 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.1, loss=modified_huber, penalty=l1;, score=0.429 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.1, loss=modified_huber, penalty=elasticnet;, score=0.378 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.1, loss=modified_huber, penalty=l1;, score=0.494 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.1, loss=modified_huber, penalty=l1;, score=0.308 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.1, loss=modified_huber, penalty=elasticnet;, score=0.466 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.1, loss=modified_huber, penalty=None;, score=0.457 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.1, loss=modified_huber, penalty=l1;, score=0.490 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.1, loss=modified_huber, penalty=l1;, score=0.513 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.1, loss=modified_huber, penalty=None;, score=0.515 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.1, loss=modified_huber, penalty=None;, score=0.337 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.1, loss=modified_huber, penalty=elasticnet;, score=0.456 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.1, loss=modified_huber, penalty=None;, score=0.499 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.1, loss=modified_huber, penalty=elasticnet;, score=0.447 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.1, loss=modified_huber, penalty=None;, score=0.444 total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SGDClassifier(max_iter=10000), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1],\n",
       "                         &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;squared_hinge&#x27;, &#x27;modified_huber&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;, None]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SGDClassifier(max_iter=10000), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1],\n",
       "                         &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;squared_hinge&#x27;, &#x27;modified_huber&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;, None]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(max_iter=10000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(max_iter=10000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SGDClassifier(max_iter=10000), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
       "                         'loss': ['hinge', 'squared_hinge', 'modified_huber'],\n",
       "                         'penalty': ['l2', 'l1', 'elasticnet', None]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"loss\" : [\"hinge\", \"squared_hinge\", \"modified_huber\"],\n",
    "    \"alpha\" : [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"penalty\" : [\"l2\", \"l1\", \"elasticnet\", None],\n",
    "}\n",
    "clf = SGDClassifier(max_iter=10000)\n",
    "grid = GridSearchCV(clf, param_grid=params, cv=5, n_jobs = -1, scoring='accuracy', verbose=3)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'alpha': 0.1, 'loss': 'squared_hinge', 'penalty': 'l1'}, 0.4785837502156288)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_, grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3283173734610123\n",
      "{'alpha': 0.1, 'loss': 'squared_hinge', 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(np.zeros((1,36)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RobustScaler()\n",
    "X_train_rob = rs.fit_transform(X_train)\n",
    "X_test_rob = rs.transform(X_test)\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "X_train_mm = mms.fit_transform(X_train)\n",
    "X_test_mm = mms.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END ...............alpha=0.0001, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END ...............alpha=0.0001, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END ...............alpha=0.0001, loss=hinge, penalty=l2; total time=   0.2s\n",
      "[CV] END ...............alpha=0.0001, loss=hinge, penalty=l1; total time=   0.2s\n",
      "[CV] END ...............alpha=0.0001, loss=hinge, penalty=l1; total time=   0.2s\n",
      "[CV] END .......alpha=0.0001, loss=hinge, penalty=elasticnet; total time=   0.5s\n",
      "[CV] END .......alpha=0.0001, loss=hinge, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END .......alpha=0.0001, loss=hinge, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END .............alpha=0.0001, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END .......alpha=0.0001, loss=hinge, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END .............alpha=0.0001, loss=hinge, penalty=None; total time=   0.2s\n",
      "[CV] END .......alpha=0.0001, loss=hinge, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END .............alpha=0.0001, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END .............alpha=0.0001, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END .......alpha=0.0001, loss=squared_hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END ...............alpha=0.0001, loss=hinge, penalty=l2; total time=   0.2s\n",
      "[CV] END .............alpha=0.0001, loss=hinge, penalty=None; total time=   0.2s\n",
      "[CV] END .......alpha=0.0001, loss=squared_hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END .......alpha=0.0001, loss=squared_hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END .......alpha=0.0001, loss=squared_hinge, penalty=l2; total time=   0.2s\n",
      "[CV] END .......alpha=0.0001, loss=squared_hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END .......alpha=0.0001, loss=squared_hinge, penalty=l1; total time=   0.3s\n",
      "[CV] END .......alpha=0.0001, loss=squared_hinge, penalty=l1; total time=   0.3s\n",
      "[CV] END .......alpha=0.0001, loss=squared_hinge, penalty=l1; total time=   0.3s\n",
      "[CV] END .......alpha=0.0001, loss=squared_hinge, penalty=l1; total time=   0.4s\n",
      "[CV] END .......alpha=0.0001, loss=squared_hinge, penalty=l1; total time=   0.2s\n",
      "[CV] END ...............alpha=0.0001, loss=hinge, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END .....alpha=0.0001, loss=squared_hinge, penalty=None; total time=   0.1s\n",
      "[CV] END .....alpha=0.0001, loss=squared_hinge, penalty=None; total time=   0.1s\n",
      "[CV] END .....alpha=0.0001, loss=squared_hinge, penalty=None; total time=   0.2s\n",
      "[CV] END .....alpha=0.0001, loss=squared_hinge, penalty=None; total time=   0.1s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END .....alpha=0.0001, loss=squared_hinge, penalty=None; total time=   0.2s\n",
      "[CV] END ......alpha=0.0001, loss=modified_huber, penalty=l2; total time=   0.2s\n",
      "[CV] END ......alpha=0.0001, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END ......alpha=0.0001, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END ......alpha=0.0001, loss=modified_huber, penalty=l2; total time=   0.2s\n",
      "[CV] END ......alpha=0.0001, loss=modified_huber, penalty=l2; total time=   0.2s\n",
      "[CV] END ......alpha=0.0001, loss=modified_huber, penalty=l1; total time=   0.2s\n",
      "[CV] END ......alpha=0.0001, loss=modified_huber, penalty=l1; total time=   0.3s\n",
      "[CV] END ......alpha=0.0001, loss=modified_huber, penalty=l1; total time=   0.3s\n",
      "[CV] END ......alpha=0.0001, loss=modified_huber, penalty=l1; total time=   0.3s\n",
      "[CV] END ...............alpha=0.0001, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END ......alpha=0.0001, loss=modified_huber, penalty=l1; total time=   0.4s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END ....alpha=0.0001, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END ....alpha=0.0001, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END ....alpha=0.0001, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END ................alpha=0.001, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END ....alpha=0.0001, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END ....alpha=0.0001, loss=modified_huber, penalty=None; total time=   0.2s\n",
      "[CV] END ................alpha=0.001, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END ................alpha=0.001, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END ................alpha=0.001, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END ................alpha=0.001, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, penalty=elasticnet; total time=   0.5s\n",
      "[CV] END ................alpha=0.001, loss=hinge, penalty=l1; total time=   0.2s[CV] END ................alpha=0.001, loss=hinge, penalty=l1; total time=   0.2s\n",
      "\n",
      "[CV] END ................alpha=0.001, loss=hinge, penalty=l1; total time=   0.2s\n",
      "[CV] END ................alpha=0.001, loss=hinge, penalty=l1; total time=   0.3s\n",
      "[CV] END ................alpha=0.001, loss=hinge, penalty=l1; total time=   0.2s\n",
      "[CV] END ...............alpha=0.0001, loss=hinge, penalty=l1; total time=   0.4s\n",
      "[CV] END ..............alpha=0.001, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ...............alpha=0.0001, loss=hinge, penalty=l1; total time=   0.4s\n",
      "[CV] END ........alpha=0.001, loss=hinge, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END ........alpha=0.001, loss=hinge, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END ........alpha=0.001, loss=hinge, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END ..............alpha=0.001, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ..............alpha=0.001, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ..............alpha=0.001, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ..............alpha=0.001, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ........alpha=0.001, loss=hinge, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END ........alpha=0.001, loss=squared_hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END ........alpha=0.001, loss=squared_hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END ........alpha=0.001, loss=hinge, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END ........alpha=0.001, loss=squared_hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END ........alpha=0.001, loss=squared_hinge, penalty=l2; total time=   0.2s\n",
      "[CV] END ........alpha=0.001, loss=squared_hinge, penalty=l1; total time=   0.2s\n",
      "[CV] END ........alpha=0.001, loss=squared_hinge, penalty=l1; total time=   0.3s[CV] END alpha=0.001, loss=squared_hinge, penalty=elasticnet; total time=   0.2s\n",
      "\n",
      "[CV] END ........alpha=0.001, loss=squared_hinge, penalty=l1; total time=   0.2s\n",
      "[CV] END ........alpha=0.001, loss=squared_hinge, penalty=l1; total time=   0.2s\n",
      "[CV] END ......alpha=0.001, loss=squared_hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ........alpha=0.001, loss=squared_hinge, penalty=l2; total time=   0.5s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END ......alpha=0.001, loss=squared_hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ......alpha=0.001, loss=squared_hinge, penalty=None; total time=   0.1s\n",
      "[CV] END .......alpha=0.001, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END .......alpha=0.001, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END .......alpha=0.001, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END ......alpha=0.001, loss=squared_hinge, penalty=None; total time=   0.2s\n",
      "[CV] END ......alpha=0.001, loss=squared_hinge, penalty=None; total time=   0.2s\n",
      "[CV] END ........alpha=0.001, loss=squared_hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END .......alpha=0.001, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END .......alpha=0.001, loss=modified_huber, penalty=l2; total time=   0.2s\n",
      "[CV] END .......alpha=0.001, loss=modified_huber, penalty=l1; total time=   0.3s\n",
      "[CV] END .......alpha=0.001, loss=modified_huber, penalty=l1; total time=   0.3s\n",
      "[CV] END .......alpha=0.001, loss=modified_huber, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.001, loss=modified_huber, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END .......alpha=0.001, loss=modified_huber, penalty=l1; total time=   0.4s\n",
      "[CV] END .....alpha=0.001, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END alpha=0.001, loss=modified_huber, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END .......alpha=0.001, loss=modified_huber, penalty=l1; total time=   0.4s\n",
      "[CV] END alpha=0.001, loss=modified_huber, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, loss=modified_huber, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END .....alpha=0.001, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END .................alpha=0.01, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END .....alpha=0.001, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END .....alpha=0.001, loss=modified_huber, penalty=None; total time=   0.2s\n",
      "[CV] END .................alpha=0.01, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END .................alpha=0.01, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END .....alpha=0.001, loss=modified_huber, penalty=None; total time=   0.2s\n",
      "[CV] END .................alpha=0.01, loss=hinge, penalty=l1; total time=   0.1s\n",
      "[CV] END .................alpha=0.01, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END .................alpha=0.01, loss=hinge, penalty=l2; total time=   0.1s\n",
      "[CV] END .................alpha=0.01, loss=hinge, penalty=l1; total time=   0.1s\n",
      "[CV] END .................alpha=0.01, loss=hinge, penalty=l1; total time=   0.1s\n",
      "[CV] END .................alpha=0.01, loss=hinge, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, loss=modified_huber, penalty=elasticnet; total time=   0.5s\n",
      "[CV] END .........alpha=0.01, loss=hinge, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END .................alpha=0.01, loss=hinge, penalty=l1; total time=   0.2s\n",
      "[CV] END .........alpha=0.01, loss=hinge, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END .........alpha=0.01, loss=hinge, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END .........alpha=0.01, loss=hinge, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END .........alpha=0.01, loss=hinge, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END ...............alpha=0.01, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ...............alpha=0.01, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ...............alpha=0.01, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ...............alpha=0.01, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ...............alpha=0.01, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, penalty=elasticnet; total time=   1.7s\n",
      "[CV] END .........alpha=0.01, loss=squared_hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END .........alpha=0.01, loss=squared_hinge, penalty=l1; total time=   0.8s\n",
      "[CV] END .........alpha=0.01, loss=squared_hinge, penalty=l1; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........alpha=0.01, loss=squared_hinge, penalty=l1; total time=  10.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........alpha=0.01, loss=squared_hinge, penalty=l2; total time=  12.7s\n",
      "[CV] END .........alpha=0.01, loss=squared_hinge, penalty=l2; total time=  12.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........alpha=0.01, loss=squared_hinge, penalty=l2; total time=  17.5s\n",
      "[CV] END .........alpha=0.01, loss=squared_hinge, penalty=l2; total time=  17.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........alpha=0.01, loss=squared_hinge, penalty=l2; total time=  17.9s\n",
      "[CV] END .......alpha=0.01, loss=squared_hinge, penalty=None; total time=   0.3s\n",
      "[CV] END .......alpha=0.01, loss=squared_hinge, penalty=None; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........alpha=0.01, loss=squared_hinge, penalty=l1; total time=  20.1s\n",
      "[CV] END .......alpha=0.01, loss=squared_hinge, penalty=None; total time=   0.4s\n",
      "[CV] END ........alpha=0.01, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END ........alpha=0.01, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END ........alpha=0.01, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END ........alpha=0.01, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END ........alpha=0.01, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END ........alpha=0.01, loss=modified_huber, penalty=l1; total time=   0.1s\n",
      "[CV] END ........alpha=0.01, loss=modified_huber, penalty=l1; total time=   0.1s\n",
      "[CV] END ........alpha=0.01, loss=modified_huber, penalty=l1; total time=   0.1s\n",
      "[CV] END ........alpha=0.01, loss=modified_huber, penalty=l1; total time=   0.1s\n",
      "[CV] END ........alpha=0.01, loss=modified_huber, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, loss=modified_huber, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, loss=modified_huber, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, loss=modified_huber, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, loss=modified_huber, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, loss=modified_huber, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END ......alpha=0.01, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END ......alpha=0.01, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END ......alpha=0.01, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END ......alpha=0.01, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END ......alpha=0.01, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END ..................alpha=0.1, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, loss=hinge, penalty=l1; total time=   0.1s\n",
      "[CV] END ..................alpha=0.1, loss=hinge, penalty=l1; total time=   0.1s\n",
      "[CV] END ..........alpha=0.1, loss=hinge, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END ..........alpha=0.1, loss=hinge, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END ..........alpha=0.1, loss=hinge, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END ..........alpha=0.1, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ..........alpha=0.1, loss=hinge, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END ................alpha=0.1, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ................alpha=0.1, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ................alpha=0.1, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ................alpha=0.1, loss=hinge, penalty=None; total time=   0.1s\n",
      "[CV] END ................alpha=0.1, loss=hinge, penalty=None; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......alpha=0.01, loss=squared_hinge, penalty=None; total time=   7.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......alpha=0.01, loss=squared_hinge, penalty=None; total time=   7.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.1, loss=squared_hinge, penalty=l2; total time=  17.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.01, loss=squared_hinge, penalty=elasticnet; total time=  40.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.1, loss=squared_hinge, penalty=l2; total time=  18.1s\n",
      "[CV] END .alpha=0.01, loss=squared_hinge, penalty=elasticnet; total time=  32.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.1, loss=squared_hinge, penalty=l2; total time=  21.0s\n",
      "[CV] END .alpha=0.01, loss=squared_hinge, penalty=elasticnet; total time=  33.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.01, loss=squared_hinge, penalty=elasticnet; total time=  36.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.1, loss=squared_hinge, penalty=l2; total time=  12.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.1, loss=squared_hinge, penalty=l2; total time=  17.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.01, loss=squared_hinge, penalty=elasticnet; total time=  42.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.1, loss=squared_hinge, penalty=l1; total time=  28.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.1, loss=squared_hinge, penalty=l1; total time=  28.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.1, loss=squared_hinge, penalty=l1; total time=  28.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.1, loss=squared_hinge, penalty=l1; total time=  39.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..alpha=0.1, loss=squared_hinge, penalty=elasticnet; total time=  28.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.1, loss=squared_hinge, penalty=l1; total time=  38.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........alpha=0.1, loss=squared_hinge, penalty=None; total time=  11.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........alpha=0.1, loss=squared_hinge, penalty=None; total time=  12.7s\n",
      "[CV] END .........alpha=0.1, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END .........alpha=0.1, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END .........alpha=0.1, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END .........alpha=0.1, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END .........alpha=0.1, loss=modified_huber, penalty=l2; total time=   0.1s\n",
      "[CV] END ..alpha=0.1, loss=squared_hinge, penalty=elasticnet; total time=  37.4s\n",
      "[CV] END .........alpha=0.1, loss=modified_huber, penalty=l1; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........alpha=0.1, loss=modified_huber, penalty=l1; total time=   0.1s\n",
      "[CV] END .........alpha=0.1, loss=modified_huber, penalty=l1; total time=   0.1s\n",
      "[CV] END .........alpha=0.1, loss=modified_huber, penalty=l1; total time=   0.1s\n",
      "[CV] END .alpha=0.1, loss=modified_huber, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END .........alpha=0.1, loss=modified_huber, penalty=l1; total time=   0.1s\n",
      "[CV] END .alpha=0.1, loss=modified_huber, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END .alpha=0.1, loss=modified_huber, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END .alpha=0.1, loss=modified_huber, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END .......alpha=0.1, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END .alpha=0.1, loss=modified_huber, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END .......alpha=0.1, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END .......alpha=0.1, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END .......alpha=0.1, loss=modified_huber, penalty=None; total time=   0.1s\n",
      "[CV] END ..alpha=0.1, loss=squared_hinge, penalty=elasticnet; total time=  37.9s\n",
      "[CV] END .......alpha=0.1, loss=modified_huber, penalty=None; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........alpha=0.1, loss=squared_hinge, penalty=None; total time=  15.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........alpha=0.1, loss=squared_hinge, penalty=None; total time=  14.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..alpha=0.1, loss=squared_hinge, penalty=elasticnet; total time=  27.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........alpha=0.1, loss=squared_hinge, penalty=None; total time=  11.4s\n",
      "[CV] END ..alpha=0.1, loss=squared_hinge, penalty=elasticnet; total time=  26.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SGDClassifier(max_iter=10000), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1],\n",
       "                         &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;squared_hinge&#x27;, &#x27;modified_huber&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;, None]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SGDClassifier(max_iter=10000), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1],\n",
       "                         &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;squared_hinge&#x27;, &#x27;modified_huber&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;, None]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(max_iter=10000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(max_iter=10000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SGDClassifier(max_iter=10000), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
       "                         'loss': ['hinge', 'squared_hinge', 'modified_huber'],\n",
       "                         'penalty': ['l2', 'l1', 'elasticnet', None]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rob = GridSearchCV(clf, param_grid=params, cv=5, n_jobs = -1, scoring='accuracy', verbose=2)\n",
    "grid_rob.fit(X_train_rob, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5321477428180574\n",
      "{'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "y_pred_rob = grid_rob.predict(X_test_rob)\n",
    "print(accuracy_score(y_test, y_pred_rob))\n",
    "print(grid_rob.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.30759686, 0.25711524, 0.4352879 ]]), array([-1,  0,  1]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rob.predict_proba(np.zeros((1,36))), grid_rob.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/javier/.pyenv/versions/3.10.6/envs/goalguru/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SGDClassifier(max_iter=10000), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1],\n",
       "                         &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;squared_hinge&#x27;, &#x27;modified_huber&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;, None]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SGDClassifier(max_iter=10000), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1],\n",
       "                         &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;squared_hinge&#x27;, &#x27;modified_huber&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;, None]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(max_iter=10000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(max_iter=10000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SGDClassifier(max_iter=10000), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
       "                         'loss': ['hinge', 'squared_hinge', 'modified_huber'],\n",
       "                         'penalty': ['l2', 'l1', 'elasticnet', None]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_mm = GridSearchCV(clf, param_grid=params, cv=5, n_jobs = -1, scoring='accuracy', verbose=1)\n",
    "grid_mm.fit(X_train_mm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5266757865937073\n",
      "{'alpha': 0.1, 'loss': 'hinge', 'penalty': None}\n"
     ]
    }
   ],
   "source": [
    "y_pred_mm = grid_mm.predict(X_test_mm)\n",
    "print(accuracy_score(y_test, y_pred_mm))\n",
    "print(grid_mm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1]), array([-1,  0,  1]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_mm.predict(np.zeros((1,36))), grid_mm.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 12:50:05.225906: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-12 12:50:05.891639: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-12 12:50:05.912665: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-12 12:50:10.183562: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Loading TensorFlow...\u001b[0m\n",
      "\n",
      "✅ TensorFlow loaded (0.0s)\n"
     ]
    }
   ],
   "source": [
    "import goalguru.soccermatch_package.ml_logic.model as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model initialized\n"
     ]
    }
   ],
   "source": [
    "model = sm.initialize_model(X_train_rob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model compiled\n"
     ]
    }
   ],
   "source": [
    "model = sm.compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat = to_categorical(y_train, num_classes=3)\n",
    "y_test_cat = to_categorical(y_test, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Training model...\u001b[0m\n",
      "✅ Model trained on 1703 rows with accuracy: 0.45\n"
     ]
    }
   ],
   "source": [
    "model, history = sm.train_model(model, X_train_rob, y_train_cat, patience=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Evaluating model on 731 rows...\u001b[0m\n",
      "✅ Model evaluated, accuracy: 0.45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 1.0420852899551392, 'accuracy': 0.4487003982067108}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = sm.evaluate_model(model, X_test_rob, y_test_cat)\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goalguru",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
